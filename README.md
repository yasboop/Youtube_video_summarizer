# YouTube Video Summarizer ğŸ¥ğŸ“

This repository provides a pipeline that:
1. **Downloads** a YouTube video.
2. **Extracts** or **transcribes** the audio.
3. **Summarizes** the transcript using a Mistral (or any other) LLM model.
4. (Optional) Extracts visual text from frames via OCR.
5. Generates a **Markdown report** summarizing the video.

---

## âœ¨ Features

- **Video Download** using `yt-dlp` ğŸš€
- **Transcript Retrieval**:
  - Automatically retrieves transcripts using `youtube-transcript-api` ğŸ¤
  - Falls back to OpenAI Whisper if no transcript is available ğŸ—£ï¸
- **Language Detection** with `langdetect` ğŸŒ
- **AI-Powered Summaries** leveraging a Mistral-based (or custom) language model ğŸ¤–
- **Optional OCR** to capture text from video frames using OpenCV and Tesseract ğŸ”
- **Structured Output**: Generates a comprehensive `.md` report including metadata, summaries, and (optional) OCR results ğŸ“„

---

## âš™ï¸ How It Works

- **Download Video:**
  - Uses `yt-dlp` to download the video file along with its metadata.

- **Transcript Handling:**
  - First tries to fetch an existing transcript with `youtube-transcript-api`.
  - If unavailable, the pipeline uses OpenAI Whisper to transcribe the audio. *(Make sure you have a valid API key if required.)*

- **Language Detection:**
  - The `langdetect` library checks the transcript language and provides this information to the summarization process.

- **Summarization:**
  - The transcript is split into manageable chunks.
  - Each chunk is fed into a Mistral-based LLM (configurable via `config.json`).
  - Summaries of each chunk are then combined into a cohesive final summary.

- **Optional OCR:**
  - If `ocr_enabled` is set to `true`, video frames are captured at specified intervals (based on `frame_interval` in seconds).
  - Tesseract OCR extracts text from each frame.
  - The recognized text is appended to the final summary or provided as an additional section in the report.

- **Markdown Report:**
  - A `.md` file is generated containing:
    - Video metadata (title, URL, duration, etc.).
    - Summaries of the transcript sections.
    - (Optional) OCR text results.
    - Final summary and conclusion.

---

## ğŸ“‚ Project Structure

```plaintext
## ğŸ› ï¸ Project Structure

```bash
Youtube_video_summarizer/
â”œâ”€â”€ debug_frames/                 # Preprocessed frames for OCR debugging
â”œâ”€â”€ frames/                       # Frames captured from the video at intervals
â”œâ”€â”€ videos/                       # Downloaded YouTube videos
â”œâ”€â”€ utils/                         # Helper functions for modularity
â”‚   â”œâ”€â”€ download.py               # Handles video downloading
â”‚   â”œâ”€â”€ transcript.py             # Retrieves/transcribes video transcripts
â”‚   â”œâ”€â”€ summarizer.py             # Summarizes transcripts using AI models
â”‚   â”œâ”€â”€ ocr.py                    # Performs OCR on video frames
â”œâ”€â”€ config.json                    # Configuration file for model settings, OCR, etc.
â”œâ”€â”€ requirements.txt                # List of required Python dependencies
â”œâ”€â”€ Video_Summarizer_Yash_Verma.ipynb  # Jupyter Notebook for demonstration
â”œâ”€â”€ Video_Summarizer_Yash_Verma.py      # Python script version (optional)
â”œâ”€â”€ summary_report.md              # Generated Markdown report of the summarized video
â”œâ”€â”€ README.md                      # This file, explaining the project

